This is a genetic algorithm that finds the best hyperparameters for training a CatBoost machine learning model. There exists a target function named `tran_models()` which adheres to all the rules and includes classes such as feature engineering, feature selection, etc., and even prevents overfitting during training. You can replace the existing data in the program with up-to-date data and see the best parameters obtained in the `ga_result.txt` file. To speed up the algorithm's execution, I used the Celery library and activated several workers on a local computer network, allowing the target function to be processed concurrently by them, which reduces the program's execution time. For this to work, you need to copy all program files to each system intended to serve as a worker and install the necessary libraries such as pandas, numpy, catboost, celery, etc., in a virtual environment (venv). Then, execute the `celery_app.py` file, after which the worker connects to the server and awaits tasks. On the server, you must also install the necessary libraries as well as RabbitMQ and Celery, define a user in RabbitMQ, and add the user's name and password to the `celery_app.py` files on the workers. Then, run the main program file, `genetic_algorithmV2.py`, and based on the parameters you define in the program, such as `population_size=150`, `generations=40`, `mutation_rate=0.02`, you will see the results in the text file mentioned earlier after some time. If you have any questions, contact me at 00989133332846 or via email at pouria.kouhzadeh@gmail.com.
